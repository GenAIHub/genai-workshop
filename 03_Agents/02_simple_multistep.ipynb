{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5e0768d5",
      "metadata": {
        "id": "5e0768d5"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GenAIHub/genai-workshop/blob/main/03_Agents/02_simple_multistep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05",
      "metadata": {
        "id": "9c48213d-6e6a-4c10-838a-2a7c710c3a05"
      },
      "source": [
        "# Multi-Step Query Engine\n",
        "\n",
        "We have a multi-step query engine that's able to decompose a complex query into sequential subquestions. This\n",
        "guide walks you through how to set it up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a71098",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20a71098",
        "outputId": "730d9029-e563-4781-fecb-2fc0051c2fb3"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install llama-index\n",
        "!pip install llama-index-llms-bedrock\n",
        "!pip install llama-index-embeddings-bedrock"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5885d63",
      "metadata": {
        "id": "c5885d63"
      },
      "source": [
        "#### Download Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee4ace96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee4ace96",
        "outputId": "499267b0-fc00-452c-ee4c-d6e14fb113e1"
      },
      "outputs": [],
      "source": [
        "!mkdir -p 'data/paul_graham/'\n",
        "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt' -O 'data/paul_graham/paul_graham_essay.txt'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119",
      "metadata": {
        "id": "50d3b817-b70e-4667-be4f-d3a0fe4bd119"
      },
      "source": [
        "#### Load documents, build the VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65ebfca2",
      "metadata": {
        "id": "65ebfca2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import boto3\n",
        "\n",
        "# Set AWS env config\n",
        "region_name = os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
        "aws_access_key_id = os.getenv(\"AWS_ACCESS_KEY_ID\", \"\")\n",
        "aws_secret_access_key = os.getenv(\"AWS_SECRET_ACCESS_KEY\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZjHJH5_A3hK7",
      "metadata": {
        "id": "ZjHJH5_A3hK7"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.bedrock import Bedrock\n",
        "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "llm_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
        "embed_model_id = \"amazon.titan-embed-text-v1\"\n",
        "\n",
        "llm = Bedrock(\n",
        "    model=llm_model_id,\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=region_name,\n",
        "    temperature=0.1,\n",
        "    max_tokens=512\n",
        "    )\n",
        "\n",
        "embed_model = BedrockEmbedding(\n",
        "    model=embed_model_id,\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=region_name,\n",
        "    )\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7",
      "metadata": {
        "id": "690a6918-7c75-4f95-9ccc-d2c4a1fe00d7"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03d1691e-544b-454f-825b-5ee12f7faa8a",
      "metadata": {
        "id": "03d1691e-544b-454f-825b-5ee12f7faa8a"
      },
      "outputs": [],
      "source": [
        "# load documents\n",
        "documents = SimpleDirectoryReader(\"./data/paul_graham/\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58",
      "metadata": {
        "id": "ad144ee7-96da-4dd6-be00-fd6cf0c78e58"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4",
      "metadata": {
        "id": "b6caf93b-6345-4c65-a346-a95b0f1746c4"
      },
      "source": [
        "#### Query Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95d989ba-0c1d-43b6-a1d3-0ea7135f43a6",
      "metadata": {
        "id": "95d989ba-0c1d-43b6-a1d3-0ea7135f43a6"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.indices.query.query_transform.base import (\n",
        "    StepDecomposeQueryTransform,\n",
        ")\n",
        "\n",
        "single_step_query_engine = index.as_query_engine(llm=llm, similarity_top_k=4)\n",
        "step_decompose_transform = StepDecomposeQueryTransform(llm=llm, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2a124db0-e2d7-4566-bcec-1d41cf669ff4",
      "metadata": {
        "id": "2a124db0-e2d7-4566-bcec-1d41cf669ff4"
      },
      "outputs": [],
      "source": [
        "index_summary = \"Ask me anything.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85466fdf-93f3-4cb1-a5f9-0056a8245a6f",
        "outputId": "960d79e4-f58e-4f8d-92ff-b0e300da6809"
      },
      "outputs": [],
      "source": [
        "# set Logging to DEBUG for more detailed outputs\n",
        "from llama_index.core.query_engine import MultiStepQueryEngine\n",
        "\n",
        "\n",
        "query_engine = MultiStepQueryEngine(\n",
        "    query_engine=single_step_query_engine,\n",
        "    query_transform=step_decompose_transform,\n",
        "    index_summary=index_summary,\n",
        "    num_steps=6\n",
        ")\n",
        "response = query_engine.query(\n",
        "    \"What were Paul Graham's achievements?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        },
        "id": "bdda1b2c-ae46-47cf-91d7-3153e8d0473b",
        "outputId": "e1172f54-425d-4df2-d3e1-1a1c93d57f2a"
      },
      "outputs": [],
      "source": [
        "display(Markdown(f\"<b>{response}</b>\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c9670bd-729d-478b-a77c-c6e13c282456",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c9670bd-729d-478b-a77c-c6e13c282456",
        "outputId": "aa067b5b-d5b0-4584-a09c-de8a8fe89cd8"
      },
      "outputs": [],
      "source": [
        "sub_qa = response.metadata[\"sub_qa\"]\n",
        "tuples = [(t[0], t[1].response) for t in sub_qa]\n",
        "print(tuples)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llama",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
