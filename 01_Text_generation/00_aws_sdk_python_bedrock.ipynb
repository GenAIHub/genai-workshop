{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDPvyYNZWsmT"
      },
      "source": [
        "# AWS SDK for Python (Boto3) - Bedrock Basic Usage with Access Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b7-q3K0dW_eV",
        "outputId": "112af19d-98de-4d5e-f802-300e8177276a"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install botocore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "XXz5xWSkW6dP"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import botocore\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxbjMLpO6M4"
      },
      "source": [
        "## AWS env config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5ahrkdecO_kR"
      },
      "outputs": [],
      "source": [
        "aws_access_key_id=\"Update with aws_access_key_id\"\n",
        "aws_secret_access_key=\"Update with aws_secret_access_key\"\n",
        "region_name=\"us-east-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0_dQy-YZezy"
      },
      "source": [
        "## Create a Boto3 client for Bedrock Runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "UfMTg4ntZgki"
      },
      "outputs": [],
      "source": [
        "client = boto3.client(\n",
        "    'bedrock-runtime',\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=region_name\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oOegBdAGu9q"
      },
      "source": [
        "## Configure Model\n",
        "\n",
        "Supported foundation models in Amazon Bedrock:\n",
        "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html\n",
        "\n",
        "Amazon Bedrock model IDs:\n",
        "https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "qHxR0KkdZ1_l"
      },
      "outputs": [],
      "source": [
        "# Specify the model ID\n",
        "model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2eqFUVJHFwD"
      },
      "source": [
        "## Configure Prompts, prepare input and Invoke the model for inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XezxOQxEqe7l",
        "outputId": "ef7486fc-f80d-4e80-8b14-c3729761c313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "    \"id\": \"msg_01GP5P44hc4SpL3ABf3gMf5Z\",\n",
            "    \"type\": \"message\",\n",
            "    \"role\": \"assistant\",\n",
            "    \"content\": [\n",
            "        {\n",
            "            \"type\": \"text\",\n",
            "            \"text\": \"Ahoy matey! Here be a tale o' high seas adventure fer ye landlubbers. 'Twas a choppy day on the briny deep, when ol' Blackbeard's galleon set sail in search o' plunder. With tattered sails and a creaky hull, we scoured the horizon fer any unsuspecting vessels. \\n\\nSuddenly, a mighty flash o' cannon fire lit up the sky! A brig from the East India Company was tryin' to outrun us, but they didn't know Blackbeard's hatred for those pompous sea dogs. We gave chase, cannonballs splashin' all around their ship's stern.  \\n\\nAfter a blisterin' broadside, their masts came tumblin' down like a drunk sailor after too much rum. We closed in fer the kill, cutlasses bared an' ready to claim our bounty. Those scurvy bilge rats surrendered without a single musket fired. We plundered that brig from stem to stern, loadin' our holds with East Indian spices, fine silks, an' plenty o' gold doubloons!\\n\\n'Twas a day that all pirates dream of - bringin' a fat prize back to port an' celebratin' with a carouse that'd make even Calypso blush! So hoist the colors ye dogs, and never forget - dead men tell no tales!\"\n",
            "        }\n",
            "    ],\n",
            "    \"model\": \"claude-3-sonnet-28k-20240229\",\n",
            "    \"stop_reason\": \"end_turn\",\n",
            "    \"stop_sequence\": null,\n",
            "    \"usage\": {\n",
            "        \"input_tokens\": 32,\n",
            "        \"output_tokens\": 317\n",
            "    }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# System and user prompts\n",
        "system_prompt = \"All your output must be pirate speech ðŸ¦œ\"\n",
        "user_prompt = \"Tell me a story.\"\n",
        "prompt = \"System:\" + system_prompt + \"\\n\\nHuman: \" + user_prompt + \"\\n\\nAssistant:\"\n",
        "\n",
        "# Prepare the input data in the required format\n",
        "input_data = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ],\n",
        "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
        "    \"max_tokens\": 2000\n",
        "}\n",
        "\n",
        "# Convert input data to JSON string\n",
        "input_data_json = json.dumps(input_data)\n",
        "\n",
        "# Specify the model ID\n",
        "model_id = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
        "\n",
        "# Invoke the model for inference\n",
        "response = client.invoke_model(\n",
        "    contentType='application/json',\n",
        "    body=input_data_json,\n",
        "    modelId=model_id\n",
        ")\n",
        "\n",
        "# Retrieve and process the inference response\n",
        "inference_result = response['body'].read().decode('utf-8')\n",
        "\n",
        "# Parse the JSON result\n",
        "parsed_result = json.loads(inference_result)\n",
        "\n",
        "# Pretty-print the JSON result\n",
        "print(json.dumps(parsed_result, indent=4))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
