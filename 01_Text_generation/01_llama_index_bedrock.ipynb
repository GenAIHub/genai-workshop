{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDPvyYNZWsmT"
      },
      "source": [
        "# LlamaIndex - Bedrock Basic Usage with Access Keys"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/GenAIHub/genai-workshop/blob/main/01_Text_generation/01_llama_index_bedrock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "5o_iZLbxUCiy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b7-q3K0dW_eV",
        "outputId": "45df4606-7c31-416a-98d3-0ffafe061e8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-bedrock\n",
            "  Downloading llama_index_llms_bedrock-0.1.12-py3-none-any.whl (8.2 kB)\n",
            "Collecting boto3<2.0.0,>=1.34.26 (from llama-index-llms-bedrock)\n",
            "  Downloading boto3-1.34.146-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-core<0.11.0,>=0.10.1 (from llama-index-llms-bedrock)\n",
            "  Downloading llama_index_core-0.10.57-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llama-index-llms-anthropic<0.2.0,>=0.1.7 (from llama-index-llms-bedrock)\n",
            "  Downloading llama_index_llms_anthropic-0.1.16-py3-none-any.whl (6.5 kB)\n",
            "Collecting botocore<1.35.0,>=1.34.146 (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock)\n",
            "  Downloading botocore-1.34.146-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.9.5)\n",
            "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2023.6.0)\n",
            "Collecting httpx (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.3)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.8.1)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.25.2)\n",
            "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading openai-1.37.0-py3-none-any.whl (337 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m337.0/337.0 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (9.4.0)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (8.5.0)\n",
            "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (4.12.2)\n",
            "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.14.1)\n",
            "Collecting anthropic<0.29.0,>=0.26.2 (from llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock)\n",
            "  Downloading anthropic-0.28.1-py3-none-any.whl (862 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m862.7/862.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (4.0.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (0.19.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.146->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.35.0,>=1.34.146->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.7)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2024.5.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (2024.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (1.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-llms-bedrock) (24.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.146->boto3<2.0.0,>=1.34.26->llama-index-llms-bedrock) (1.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (0.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<0.29.0,>=0.26.2->llama-index-llms-anthropic<0.2.0,>=0.1.7->llama-index-llms-bedrock) (3.15.4)\n",
            "Installing collected packages: dirtyjson, mypy-extensions, marshmallow, jmespath, jiter, h11, deprecated, typing-inspect, tiktoken, httpcore, botocore, s3transfer, httpx, dataclasses-json, openai, boto3, anthropic, llama-index-core, llama-index-llms-anthropic, llama-index-llms-bedrock\n",
            "Successfully installed anthropic-0.28.1 boto3-1.34.146 botocore-1.34.146 dataclasses-json-0.6.7 deprecated-1.2.14 dirtyjson-1.0.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 jmespath-1.0.1 llama-index-core-0.10.57 llama-index-llms-anthropic-0.1.16 llama-index-llms-bedrock-0.1.12 marshmallow-3.21.3 mypy-extensions-1.0.0 openai-1.37.0 s3transfer-0.10.2 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install llama-index-llms-bedrock"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XXz5xWSkW6dP"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.bedrock import Bedrock\n",
        "from llama_index.core.llms import ChatMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxbjMLpO6M4"
      },
      "source": [
        "## AWS env config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5ahrkdecO_kR"
      },
      "outputs": [],
      "source": [
        "aws_access_key_id=\"Update_with_aws_access_key_id\"\n",
        "aws_secret_access_key=\"Update_with_aws_secret_access_key\"\n",
        "region_name=\"us-east-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oOegBdAGu9q"
      },
      "source": [
        "## Configure Model\n",
        "\n",
        "Supported foundation models in Amazon Bedrock:\n",
        "https://docs.aws.amazon.com/bedrock/latest/userguide/models-supported.html\n",
        "\n",
        "Amazon Bedrock model IDs:\n",
        "https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hh3AiWaYWsmU",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "llm = Bedrock(\n",
        "    model=\"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
        "    aws_access_key_id=aws_access_key_id,\n",
        "    aws_secret_access_key=aws_secret_access_key,\n",
        "    region_name=region_name,\n",
        "    temperature=0.1,\n",
        "    max_tokens=512\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2eqFUVJHFwD"
      },
      "source": [
        "## Configure Prompts and Call chat with a list of messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XezxOQxEqe7l",
        "outputId": "6759feaa-4b93-412c-c2e7-c8f317d59c98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assistant: 🏴‍☠️ Ahoy matey! Let me spin ye a tale o' high seas adventure. 'Twas a balmy night on the Spanish Main when the dreaded pirate ship, the Crimson Serpent, sailed into view. Her fearsome crew was led by the scurvy dog Cap'n Redbeard, a pirate so vile, even Davy Jones' locker turned away in fear!\n",
            "\n",
            "They had just plundered a galleon laden with Spanish gold, but Redbeard's thirst for treasure could ne'er be sated. Word reached his ear o' a fabled island where an ancient treasure lay buried - the Lost Bounty o' the Calico Jack! Without delay, they charted a course through treacherous waters in pursuit o' this prize.\n",
            "\n",
            "Storms battered the ship as they braved the Devil's Maw, a cursed strait where ships went in but none returned. Shiver me timbers, even Redbeard's salty crew began to fear the worst! But their cap'n's lust for riches drove them onward until at last they dropped anchor at the island's black volcanic shores.\n",
            "\n",
            "'Twas there they faced horrific challenges - cannibal tribes, giant crustaceans, even an undead scourge o' pirate zombies! But no phantoms nor beasties could deter brave Redbeard from claimin' the Calico Jack's treasure. After battlin' their way through, they finally uncovered the fabled bounty - a king's ransom in jewels, gold, and exotic plunder!\n",
            "\n",
            "With their hard-won riches secured, they set sail once more into the sunset, Redbeard's laughter echoin' across the waves. And that's the tale of how the vilest pirate to ever sail the Spanish Main added the Lost Bounty to his vast hoard of ill-gotten gains! Arrrr!\n"
          ]
        }
      ],
      "source": [
        "system_prompt=\"All your output must be pirate speech 🦜\"\n",
        "user_prompt = \"Tell me a story.\"\n",
        "\n",
        "resp = llm.chat(\n",
        "    [\n",
        "    ChatMessage(role=\"system\", content=system_prompt),\n",
        "    ChatMessage(role=\"user\", content=user_prompt),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}