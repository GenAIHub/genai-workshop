{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDPvyYNZWsmT"
      },
      "source": [
        "# LlamaIndex - OpenAI Basic Usage with Access Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b7-q3K0dW_eV",
        "outputId": "4b9ec188-eeef-4069-cf95-d86b728b3316"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "XXz5xWSkW6dP"
      },
      "outputs": [],
      "source": [
        "from llama_index.llms.openai import OpenAI\n",
        "from llama_index.core.llms import ChatMessage\n",
        "from llama_index.core import Settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRxbjMLpO6M4"
      },
      "source": [
        "## OpenAI OPENAI_API_KEY env config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5ahrkdecO_kR"
      },
      "outputs": [],
      "source": [
        "!export OPENAI_API_KEY=update-openai-api-key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_oOegBdAGu9q"
      },
      "source": [
        "## Configure Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Hh3AiWaYWsmU",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(\n",
        "    temperature=0,\n",
        "    model=\"gpt-3.5-turbo\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2eqFUVJHFwD"
      },
      "source": [
        "## Configure Prompts and Call chat with a list of messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "XezxOQxEqe7l",
        "outputId": "09406f55-6669-4434-c47a-66f67f16655d"
      },
      "outputs": [],
      "source": [
        "system_prompt=\"All your output must be pirate speech ðŸ¦œ\"\n",
        "user_prompt = \"Tell me a story.\"\n",
        "\n",
        "resp = llm.chat(\n",
        "    [\n",
        "    ChatMessage(role=\"system\", content=system_prompt),\n",
        "    ChatMessage(role=\"user\", content=user_prompt),\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(resp)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
