{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxNdO6CtvT8t"
      },
      "outputs": [],
      "source": [
        "!pip install boto3\n",
        "!pip install pydantic==1.10.9\n",
        "!pip installl lama_index\n",
        "!pip install llama-index-embeddings-bedrock==0.1.4\n",
        "!pip install llama-index-llms-bedrock==0.1.5\n",
        "!pip install llama-index-vector-stores-postgres==0.1.5\n",
        "!pip install langchain==0.0.333\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S93_NKV3Ab4l"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index-readers-file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nkztbgvWvjJi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.mkdir(\"./data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0cghk1mavusG"
      },
      "outputs": [],
      "source": [
        "import fitz\n",
        "\n",
        "doc = fitz.open(\"./data/motorola3.pdf\")\n",
        "full_pdf_content = \"\"\n",
        "for page in range(doc.page_count):\n",
        "  pg = doc.load_page(page)\n",
        "  text = pg.get_text()\n",
        "  full_pdf_content += text\n",
        "\n",
        "print(full_pdf_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDdrLo6Yvw-F"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser.text.sentence import SentenceSplitter\n",
        "from llama_index.core.schema import Document\n",
        "import pprint as pp\n",
        "\n",
        "chunk_size = 1024\n",
        "chunk_overlap = 100\n",
        "\n",
        "splitter = SentenceSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        # chunk_size=512,\n",
        "        chunk_overlap=chunk_overlap,\n",
        "    )\n",
        "\n",
        "docs = splitter.get_nodes_from_documents(\n",
        "        [\n",
        "            Document(\n",
        "                text=full_pdf_content,\n",
        "                metadata={\n",
        "                    \"page\": 0,\n",
        "                    #\"file_name\": f\"{metadata_file_name}\",\n",
        "                    \"source\": \"text\",\n",
        "                    \"document_id\": f\"some_id\",\n",
        "                },\n",
        "                excluded_embed_metadata_keys=[\"page\", \"source\", \"document_id\"],\n",
        "                excluded_llm_metadata_keys=[\"page\", \"source\", \"document_id\"],\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "pp.pprint(docs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JKRSxBzlv98x"
      },
      "outputs": [],
      "source": [
        "from llama_index.embeddings.bedrock import BedrockEmbedding\n",
        "from llama_index.llms.bedrock import Bedrock\n",
        "from llama_index.core.settings import Settings\n",
        "import boto3\n",
        "import asyncio\n",
        "import os\n",
        "\n",
        "\n",
        "os.environ[\"AWS_REGION\"] = \"us-east-1\"\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"\"\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"\"\n",
        "os.environ[\"AWS_SESSION_TOKEN\"] = \"\"\n",
        "\n",
        "embed_model_id = \"amazon.titan-embed-text-v1\"\n",
        "llm_model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
        "\n",
        "BEDROCK_CLIENT = boto3.client(\"bedrock-runtime\", \"us-east-1\")\n",
        "\n",
        "llm = Bedrock(\n",
        "    model=llm_model_id, client=BEDROCK_CLIENT, aws_region_name=\"us-east-1\")\n",
        "embed_model = BedrockEmbedding(model=embed_model_id, client=BEDROCK_CLIENT)\n",
        "\n",
        "Settings.llm = llm\n",
        "Settings.embed_model = embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzKd4HTUwAMH"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.ingestion.pipeline import IngestionPipeline\n",
        "from llama_index.core.extractors import QuestionsAnsweredExtractor\n",
        "import asyncio\n",
        "\n",
        "pipeline = IngestionPipeline(\n",
        "          transformations=[\n",
        "              QuestionsAnsweredExtractor(questions=2)\n",
        "           ]\n",
        "      )\n",
        "nodes = await pipeline.arun(nodes = docs)\n",
        "pp.pprint(nodes[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aYL5Xha3qg6"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "index =  VectorStoreIndex(nodes)\n",
        "\n",
        "print(index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y3LYWu47U0Z"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine(similarity_top_k=2)\n",
        "response = query_engine.query(\"What is this document about?\")\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx6hS2oy0pmp"
      },
      "outputs": [],
      "source": [
        "for n in response.source_nodes:\n",
        "  print(n)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}